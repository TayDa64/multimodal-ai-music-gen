# üéµ Multimodal AI Music Generator: The Complete Guide

> **Transform natural language into production-ready music projects with MIDI, audio, and MPC export.**

## üìñ Table of Contents
1. [Introduction](#-introduction)
2. [Setup & Installation](#-setup--installation)
3. [Core Workflows](#-core-workflows)
4. [The Output Ecosystem](#-the-output-ecosystem)
5. [The AI Production Brain](#-the-ai-production-brain)
6. [Advanced Features](#-advanced-features)
7. [Developer Guide](#-developer-guide)
8. [Summary & Roadmap](#-summary--roadmap)

---

## üéØ Introduction
The **Multimodal AI Music Generator** is a sophisticated ecosystem bridging the gap between natural language intention and professional music production. It allows creators to describe a musical vision‚Äîe.g., *"A dark trap soul beat at 87 BPM in C minor"*‚Äîand transforms that text into a fully realized production environment with MIDI, rendered stems, and complete **Akai MPC Projects (.xpj)**.

---

## üöÄ Setup & Installation

### Python Backend (The Brain)
The generator requires Python 3.12+ for orchestration, NLP, and audio rendering.
1. **Dependencies**: `pip install -r requirements.txt`
2. **Advanced Features**: For YouTube analysis and MIDI hardware support:
   `pip install librosa yt-dlp python-rtmidi`
3. **Audio Engine**: Install **FluidSynth** for high-quality instrument textures.
   - **Windows**: `choco install fluidsynth`
   - **SoundFonts**: Place `.sf2` files in `assets/soundfonts/`.

### JUCE Frontend (The Body)
The C++ UI provides a high-performance environment for mixing and arrangement.
1. Navigate to the `juce/` directory.
2. Use **CMake** to generate project files for your IDE.
3. Build the `MusicGenerator` target to run the standalone application.

---

## üéπ Core Workflows

### 1. Text-to-Music (Simple Generation)
The primary entry point. Describe your prompt:
`python main.py "nostalgic lofi hip hop with rainy textures" --mpc`
The AI analyzes mood, tempo, and instruments to build a custom arrangement.

### 2. Reference-Based Analysis
Extract musical DNA from existing tracks using the `--reference` flag:
- **Parameters**: Extracts precise BPM, Key, Genre, and Spectral Profile.
- **Groove**: Quantifies "swing" to apply authentic rhythmic feel.

### 3. MIDI Hardware Integration
Record live performances (e.g., MPC pads) directly into the generator:
`python main.py --record-part drums --midi-in "MPC Studio" --record-bars 8`

### 4. JUCE GUI Interaction
- **Timeline**: Visualize arrangement sections in [TimelineComponent.cpp](juce/Source/UI/TimelineComponent.cpp).
- **Mixer**: Professional channel strips with Gain, Pan, and Mute/Solo in [MixerComponent.cpp](juce/Source/UI/Mixer/MixerComponent.cpp).
- **Take Lanes**: Audition multiple AI variations and "comp" the best sections using [TakeLaneComponent.cpp](juce/Source/UI/TakeLaneComponent.cpp).

---

## üìÅ The Output Ecosystem

The system prioritizes **editability** and **authorship** over static renders:
- **MIDI**: High-resolution 480 PPQ files for any DAW, generated by [midi_generator.py](multimodal_gen/midi_generator.py).
- **WAV Stems**: Individual tracks rendered via [audio_renderer.py](multimodal_gen/audio_renderer.py) with [BWF Metadata](multimodal_gen/bwf_writer.py) for AI-Act compliance and authorship tracking.
- **MPC Projects (.xpj)**: Complete project folders with `.xpm` programs and mapped samples, exported by [mpc_exporter.py](multimodal_gen/mpc_exporter.py).

---

## üß† The AI Production Brain

The "brain" of the system is a multi-layered decision engine that translates human intent into musical structures.

### 1. Intent & Genre Intelligence
- **Prompt Analysis**: The [prompt_parser.py](multimodal_gen/prompt_parser.py) extracts BPM, Key, and "Sonic Adjectives" (e.g., "dark", "hype").
- **Genre Intelligence**: The [genre_intelligence.py](multimodal_gen/genre_intelligence.py) provides deep genre understanding with structured templates, mandatory/forbidden elements, spectral profiles, and FX chains.
- **Style Policy**: The [style_policy.py](multimodal_gen/style_policy.py) acts as the **"Producer Brain"**, consolidating genre rules and groove templates into a unified [PolicyContext](multimodal_gen/style_policy.py#L298).

### 2. The Session Graph (Source of Truth)
The [session_graph.py](multimodal_gen/session_graph.py) serves as the central contract between Python and JUCE. It represents the song as a structured tree of:
- **Sections**: Energy-aware markers (Intro, Verse, Drop) defined in [SectionMarker](multimodal_gen/session_graph.py#L400).
- **Tracks & Roles**: Semantic assignments (DRUMS, BASS, LEAD) using the [Role](multimodal_gen/session_graph.py#L58) system.
- **Take Lanes**: Strategic variations managed by the [TakeGenerator](multimodal_gen/take_generator.py) and tracked in [Clip](multimodal_gen/session_graph.py#L182).

### 3. Musical & Composition Intelligence
- **Motif Engine**: The [motif_engine.py](multimodal_gen/motif_engine.py) generates short, memorable musical ideas (intervals, rhythms, accents) that can be developed throughout a composition.
- **Tension Arc**: The [tension_arc.py](multimodal_gen/tension_arc.py) creates emotional narrative curves that modulate dynamics, note density, and harmonic complexity across arrangements.

### 4. Musical Intelligence
- **Rhythmic Humanization**: [drum_humanizer.py](multimodal_gen/drum_humanizer.py) and [microtiming.py](multimodal_gen/microtiming.py) apply "pocket" feel and velocity dynamics.
- **Genre Logic**: [genre_rules.py](multimodal_gen/genre_rules.py) enforces mandatory elements (e.g., 808s in Trap) and forbids stylistic clashes.
- **Micro-Variation**: The [take_generator.py](multimodal_gen/take_generator.py) produces "Takes" for each clip, allowing users to select the perfect performance.

### 5. Synthesis & Mixing
- **Instrument Intelligence**: The [instrument_intelligence.py](multimodal_gen/instrument_intelligence.py) provides semantic understanding of instruments and intelligent selection based on genre, mood, and song requirements.
- **Hybrid Synthesis**: Real-time tones via [assets_gen.py](multimodal_gen/assets_gen.py) and high-fidelity sampling via [sample_loader.py](multimodal_gen/sample_loader.py).
- **Mix Engine**: A Python-based [mix_engine.py](multimodal_gen/mix_engine.py) handles initial levels, while the JUCE [MixerGraph.cpp](juce/Source/Audio/MixerGraph.cpp) manages real-time DSP.

---

## ‚ú® Advanced Features

### Ethiopian Traditional Instruments
Authentic support for the **Krar** (lyre), **Masenqo** (fiddle), and **Begena** (bass) with physical modeling and traditional scales (Tizita, Ambassel, etc.). Logic resides in [ethio_melody.py](multimodal_gen/ethio_melody.py) and detailed in [ETHIOPIAN_INSTRUMENTS.md](docs/ETHIOPIAN_INSTRUMENTS.md).

### Instrument Shaper
Interactive spectral editor [instrument_shaper.py](instrument_shaper.py) (supported by [spectrum_viewer.py](spectrum_viewer.py)) allowing users to drag harmonic nodes to sculpt timbres in real-time.

### Expansion System
Sophisticated management for adding new sample packs and "Sonic Adjectives" via [expansion_manager.py](multimodal_gen/expansion_manager.py).

---

## üë®‚Äçüíª Developer Guide

### Architecture
- **Client**: JUCE C++ (UI, OSC Client) in [juce/Source/](juce/Source/).
- **Server**: Python 3.12 (Composition engine, OSC Server) in [multimodal_gen/](multimodal_gen/).
- **Bridge**: OSC (Open Sound Control) protocol documented in [PROTOCOL.md](PROTOCOL.md).

### Key Files & Entry Points
1. **Server Entry**: [main.py](main.py) - Orchestrates the entire generation pipeling.
2. **OSC Contract**: [PROTOCOL.md](PROTOCOL.md) - Defines endpoints like `/generate` and `/take/comp`.
3. **Session State**: `session_manifest.json` - Serialized version of [SessionGraph](multimodal_gen/session_graph.py).

---

## üìà Summary & Roadmap
The Multimodal AI Music Generator provides the **scaffolding** for creativity.
**Next Steps**: Microtuning engine, VST3 plugin hosting, and advanced AI "comping" UI.
